{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.验证模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from base_module import *\n",
    "\n",
    "from pymahjong import *\n",
    "from pymahjong import MahjongPyWrapper as pm\n",
    "from pymahjong.myEnv_pymahjong import myMahjongEnv\n",
    "\n",
    "env = myMahjongEnv()\n",
    "env.reset()\n",
    "\n",
    "\n",
    "# 检测GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# 测试用输入\n",
    "batch =  []\n",
    "batch_size = 16\n",
    "feature_channels = 35\n",
    "feature_height = 4\n",
    "feature_width = 9\n",
    "\n",
    "action_space = 47\n",
    "\n",
    "while len(batch) < batch_size:\n",
    "    while not env.is_over():\n",
    "        curr_pid = env.get_curr_player_id()\n",
    "        valid_actions = env.get_valid_actions()\n",
    "        action = np.random.choice(valid_actions)\n",
    "        env.step(player_id=curr_pid, action=action)\n",
    "    print(env.get_payoffs())\n",
    "    for i in range(4):\n",
    "        batch.append(env.get_observation_with_return(i))\n",
    "    env.reset()\n",
    "collator = myCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_module import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "\n",
    "# 检测GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "# 创建模型\n",
    "config = GPT2Config(n_embd=512, n_layer=8, n_head=8, n_positions=128)\n",
    "model = Policy_Network(config).to(device)\n",
    "data = collator(batch)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = model.forward(**data)\n",
    "print(\"action_logits:\", output[\"action_logits\"].shape)\n",
    "print(output[\"action_logits\"][0])\n",
    "print(\"probs:\", output[\"action_probs\"][0])\n",
    "# print(\"loss:\", output[\"loss\"])\n",
    "print(\"action:\", output[\"action\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.验证麻将环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymahjong import *\n",
    "from pymahjong import MahjongPyWrapper as pm\n",
    "from pymahjong.myEnv_pymahjong import myMahjongEnv\n",
    "\n",
    "env = myMahjongEnv()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.get_valid_actions())\n",
    "print(env.legal_actions_mask_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not env.is_over():\n",
    "    curr_pid = env.get_curr_player_id()\n",
    "    valid_actions = env.get_valid_actions()\n",
    "    action = np.random.choice(valid_actions)\n",
    "    env.step(player_id=curr_pid, action=action)\n",
    "print(env.get_payoffs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 展示当前phase和合法动作列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase, aviable_action = env._proceed()\n",
    "print(\"phase:\", phase)\n",
    "for idx, action in enumerate(aviable_action):\n",
    "    print(idx, action.to_string())\n",
    "\n",
    "valid_action = env.get_valid_actions()\n",
    "print(\"valid_action:\", valid_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 执行动作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(\"player\", i, \"hand:\", env._get_hand_tiles(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.get_observation(1)\n",
    "print(\"tiles_features shape:\", obs['tiles_features'].shape)\n",
    "print(\"oya shape:\", obs['info']['oya'].shape)\n",
    "print(\"riichi_sticks shape:\", obs['info']['riichi_sticks'].shape)\n",
    "print(\"action_list shape:\", obs['action_list'].shape)\n",
    "print(\"action_list:\", obs['action_list'])\n",
    "print(\"self_action_mask shape:\", obs['self_action_mask'].shape)\n",
    "print(\"self_action_mask:\", obs['self_action_mask'])\n",
    "print(\"sum self_action_mask:\", obs['self_action_mask'].sum())\n",
    "print(\"attention_mask shape:\", obs['attention_mask'].shape)\n",
    "print(\"attention_mask:\", obs['attention_mask'])\n",
    "print(\"Q shape:\", obs['Q_values'].shape)\n",
    "print(\"Q:\", obs['Q_values'])\n",
    "print(\"legal_action_mask shape:\", obs['legal_action_mask'].shape)\n",
    "print(\"legal_action_mask:\", obs['legal_action_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(\"player\", i, \"fuuros:\", env._get_fuuros(i))\n",
    "    print(\"points:\", env._get_points(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.使用模型来决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "\n",
    "# 使用第一个可用的 GPU，即设备 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from base_module import *\n",
    "\n",
    "from pymahjong import *\n",
    "from pymahjong import MahjongPyWrapper as pm\n",
    "from pymahjong.myEnv_pymahjong import myMahjongEnv\n",
    "\n",
    "env = myMahjongEnv()\n",
    "env.reset()\n",
    "\n",
    "config = GPT2Config(n_embd=512, n_layer=8, n_head=8, n_positions=128)\n",
    "model = Policy_Network(config).to(device)\n",
    "model.eval()\n",
    "\n",
    "collator = myCollator()\n",
    "for i in range(100):\n",
    "    while not env.is_over():\n",
    "        curr_pid = env.get_curr_player_id()\n",
    "        obs = env.get_observation(curr_pid)\n",
    "        input = {\n",
    "        \"tiles_features\": torch.tensor(obs['tiles_features'], dtype=torch.float32).to(device),\n",
    "        \"oya\": torch.tensor(obs['info']['oya'], dtype=torch.float32).unsqueeze(0).to(device),\n",
    "        \"riichi_sticks\": torch.tensor(obs['info']['riichi_sticks'],dtype=torch.float32).unsqueeze(0).to(device),\n",
    "        \"action_list\": torch.tensor(obs['action_list'],dtype=torch.long).unsqueeze(0).to(device),\n",
    "        \"attention_mask\": torch.tensor(obs['attention_mask'],dtype=torch.long).unsqueeze(0).to(device),\n",
    "        \"legal_action_mask\": torch.tensor(obs['legal_action_mask'], dtype=bool).to(device)\n",
    "        }\n",
    "        output = model.inference(**input)\n",
    "        action = output[\"action\"].item()\n",
    "        env.step(player_id=curr_pid, action=action)\n",
    "        # print(\"player:\", curr_pid, \"action:\", action)\n",
    "    print(env.get_payoffs())\n",
    "    env.reset()\n",
    "\n",
    "\n",
    "\n",
    "# print(\"action:\", output[\"action\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_device: cuda:0\n",
      "training_device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import torch\n",
    "\n",
    "# 使用第一个可用的 GPU，即设备 1\n",
    "inference_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "training_device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"inference_device:\", inference_device)\n",
    "print(\"training_device:\", training_device)\n",
    "\n",
    "import numpy as np\n",
    "from base_module import *\n",
    "\n",
    "from pymahjong import *\n",
    "from pymahjong import MahjongPyWrapper as pm\n",
    "from pymahjong.myEnv_pymahjong import myMahjongEnv\n",
    "\n",
    "env = myMahjongEnv()\n",
    "env.reset()\n",
    "\n",
    "config = GPT2Config(n_embd=512, n_layer=8, n_head=8, n_positions=128)\n",
    "inference_model = Policy_Network(config).to(inference_device)\n",
    "inference_model.eval()\n",
    "\n",
    "training_model = Policy_Network(config).to(training_device)\n",
    "training_model.load_state_dict(inference_model.state_dict())\n",
    "training_model.train()\n",
    "\n",
    "collator = myCollator(device=training_device)\n",
    "optimizer = torch.optim.Adam(training_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_430256/1141062997.py:16: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \"legal_action_mask\": torch.tensor(obs['legal_action_mask'], dtype=bool).to(inference_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0. -2000.     0.  2000.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-1000. -1000.  3000. -1000.]\n",
      "[-1000. -1000. -1000.  3000.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "loss: -4830.759765625\n",
      "loss: -0.0\n",
      "loss: -0.0\n",
      "loss: -0.0\n",
      "loss: -0.0\n",
      "loss: -0.0\n",
      "loss: -17482.611328125\n",
      "loss: -2279.8203125\n",
      "loss: -0.0\n",
      "loss: -0.0\n",
      "[ 1500. -1500. -1500.  1500.]\n",
      "[ 2700.  -700. -1300.  -700.]\n",
      "-------------- execption in make_selection_from_action_basetile ------------------\n",
      "Cannot locate action with action = 0\n",
      "BaseAction.Pass []\n",
      "[[1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "----------- current player: 3 -----------------\n",
      "[Player 0]\n",
      "Pt: 25000\n",
      "Wind: North\n",
      "Hand: 0m 3p 1s 9s 3z 3z 5z \n",
      "Calls: 2p3p(4p) 3m4m(5m) \n",
      "River: 7p4h 7p8h 9p12h 7m18h- 1p22 6s26h 6s30 5p34h 8s38 2z42h 2m46h 5p50h 1z54 5p58 7z62h 7s66 \n",
      "Riichi: No\n",
      "Menzen: No\n",
      "[Player 1]\n",
      "Pt: 25000\n",
      "Wind: East\n",
      "Hand: 4m 8m 9m 3p 4s 5s 3z 3z 4z 6z \n",
      "Calls: 5m6m(7m) \n",
      "River: 1z1h 1z5h 4p9h 4p13 7p19h 6m23h 7m27h 1p31h 6s35h- 1p39h 2z43h 3s47h 2s51h 6p55h 2s59h 7z63 7m67 \n",
      "Riichi: No\n",
      "Menzen: No\n",
      "[Player 2]\n",
      "Pt: 25000\n",
      "Wind: South\n",
      "Hand: 1m 1m 1s 4s 4s 5z 6z \n",
      "Calls: 3s3s(3s) 4s5s(6s) \n",
      "River: 6m2h 2z6h 8p10 6s14h 2m16h 3m20h 2m24 3m28h 9s32h 9s36h 4z40h 4z44h 8p48 8s52 8m56h 4p60 2m64 8s68 \n",
      "Riichi: No\n",
      "Menzen: No\n",
      "[Player 3]\n",
      "Pt: 25000\n",
      "Wind: West\n",
      "Hand: 1m 1m 8m 9m 9m 3p 1s 1s 0s 5s 5z 6z 6z 5z \n",
      "River: 8s3h 1p7h 7s11 3s15h- 7z17h 6p21h 4p25- 7p29 6p33h 2s37h 2s41h 0p45 7z49h 9p53 1z57 5m61h- 9s65h \n",
      "Riichi: No\n",
      "Menzen: Yes\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/mahjong/src/RL/pymahjong/env_pymahjong.py:211\u001b[0m, in \u001b[0;36mMahjongEnv.step\u001b[0;34m(self, player_id, action)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_selection_from_action_basetile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43maction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorresponding_tiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAHJONG_TILE_TYPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inst:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot locate action with action = 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m inference_model\u001b[38;5;241m.\u001b[39minference(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     19\u001b[0m     action \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 20\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_pid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     22\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mappend(env\u001b[38;5;241m.\u001b[39mget_observation_with_return(i))\n",
      "File \u001b[0;32m~/Code/mahjong/src/RL/pymahjong/myEnv_pymahjong.py:379\u001b[0m, in \u001b[0;36mmyMahjongEnv.step\u001b[0;34m(self, player_id, action)\u001b[0m\n\u001b[1;32m    375\u001b[0m tiles_features, oya \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tiles_features(player_id)\n\u001b[1;32m    378\u001b[0m legal_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_legal_actions_mask()\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegal_actions_mask_record[player_id]\u001b[38;5;241m.\u001b[39mappend(legal_actions)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles_features_record[player_id]\u001b[38;5;241m.\u001b[39mappend(tiles_features)\n",
      "File \u001b[0;32m~/Code/mahjong/src/RL/pymahjong/env_pymahjong.py:221\u001b[0m, in \u001b[0;36mMahjongEnv.step\u001b[0;34m(self, player_id, action)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28mprint\u001b[39m(obs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemError\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# riichi step 2\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRIICHI, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPASS_RIICHI)\n",
      "\u001b[0;31mSystemError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "num_games = 10\n",
    "for i in range(epoch): \n",
    "   # 生成10局对局数据\n",
    "    dataset = []\n",
    "    for i in range(num_games):\n",
    "        while not env.is_over():\n",
    "            curr_pid = env.get_curr_player_id()\n",
    "            obs = env.get_observation(curr_pid)\n",
    "            input = {\n",
    "            \"tiles_features\": torch.tensor(obs['tiles_features'], dtype=torch.float32).to(inference_device),\n",
    "            \"oya\": torch.tensor(obs['info']['oya'], dtype=torch.float32).unsqueeze(0).to(inference_device),\n",
    "            \"riichi_sticks\": torch.tensor(obs['info']['riichi_sticks'],dtype=torch.float32).unsqueeze(0).to(inference_device),\n",
    "            \"action_list\": torch.tensor(obs['action_list'],dtype=torch.long).unsqueeze(0).to(inference_device),\n",
    "            \"attention_mask\": torch.tensor(obs['attention_mask'],dtype=torch.long).unsqueeze(0).to(inference_device),\n",
    "            \"legal_action_mask\": torch.tensor(obs['legal_action_mask'], dtype=bool).to(inference_device)\n",
    "            }\n",
    "            output = inference_model.inference(**input)\n",
    "            action = output[\"action\"].item()\n",
    "            env.step(player_id=curr_pid, action=action)\n",
    "        for i in range(4):\n",
    "            dataset.append(env.get_observation_with_return(i))\n",
    "        print(env.get_payoffs())\n",
    "        env.reset()\n",
    "\n",
    "    # 从dataset中每次取出batch_size个数据\n",
    "    batch_size = 4\n",
    "    collator = myCollator()\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch = dataset[i:i+batch_size]\n",
    "        data = collator(batch)\n",
    "        # 移动数据到training_device\n",
    "        for key in data.keys():\n",
    "            if key == \"info\":\n",
    "                for sub_key in data[key].keys():\n",
    "                    data[key][sub_key] = data[key][sub_key].to(training_device)\n",
    "            else:\n",
    "                data[key] = data[key].to(training_device)\n",
    "        output = training_model.forward(**data)\n",
    "        loss = output[\"loss\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"loss:\", loss.item())\n",
    "\n",
    "    # 将training_model的参数复制到inference_model,并保存checkpoint\n",
    "    inference_model.load_state_dict(training_model.state_dict())\n",
    "    torch.save(inference_model.state_dict(), f\"./checkpoints/epoch_{epoch}.pth\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 3\n",
      "player: 3\n",
      "legal actions: [ 0  7  8 11 18 22 31 32 45]\n",
      "action 45\n",
      "nonzero_index: [0, 7, 8, 11, 18, 22, 31, 32, 41, 45]\n"
     ]
    }
   ],
   "source": [
    "print(\"phase:\", env.t.get_phase())\n",
    "print(\"player:\", env.get_curr_player_id())\n",
    "print(\"legal actions:\", env.get_valid_actions())\n",
    "print(\"action\", action)\n",
    "action_container = env.act_container\n",
    "nonzero_index = [i for i in range(len(action_container)) if action_container[i] != 0]\n",
    "print(\"nonzero_index:\", nonzero_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- execption in make_selection_from_action_basetile ------------------\n",
      "Cannot locate action with action = 0\n",
      "BaseAction.Pass []\n",
      "[[1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "----------- current player: 3 -----------------\n",
      "[Player 0]\n",
      "Pt: 25000\n",
      "Wind: North\n",
      "Hand: 0m 3p 1s 9s 3z 3z 5z \n",
      "Calls: 2p3p(4p) 3m4m(5m) \n",
      "River: 7p4h 7p8h 9p12h 7m18h- 1p22 6s26h 6s30 5p34h 8s38 2z42h 2m46h 5p50h 1z54 5p58 7z62h 7s66 \n",
      "Riichi: No\n",
      "Menzen: No\n",
      "[Player 1]\n",
      "Pt: 25000\n",
      "Wind: East\n",
      "Hand: 4m 8m 9m 3p 4s 5s 3z 3z 4z 6z \n",
      "Calls: 5m6m(7m) \n",
      "River: 1z1h 1z5h 4p9h 4p13 7p19h 6m23h 7m27h 1p31h 6s35h- 1p39h 2z43h 3s47h 2s51h 6p55h 2s59h 7z63 7m67 \n",
      "Riichi: No\n",
      "Menzen: No\n",
      "[Player 2]\n",
      "Pt: 25000\n",
      "Wind: South\n",
      "Hand: 1m 1m 1s 4s 4s 5z 6z \n",
      "Calls: 3s3s(3s) 4s5s(6s) \n",
      "River: 6m2h 2z6h 8p10 6s14h 2m16h 3m20h 2m24 3m28h 9s32h 9s36h 4z40h 4z44h 8p48 8s52 8m56h 4p60 2m64 8s68 \n",
      "Riichi: No\n",
      "Menzen: No\n",
      "[Player 3]\n",
      "Pt: 25000\n",
      "Wind: West\n",
      "Hand: 1m 1m 8m 9m 9m 3p 1s 1s 0s 5s 5z 6z 6z 5z \n",
      "River: 8s3h 1p7h 7s11 3s15h- 7z17h 6p21h 4p25- 7p29 6p33h 2s37h 2s41h 0p45 7z49h 9p53 1z57 5m61h- 9s65h \n",
      "Riichi: No\n",
      "Menzen: Yes\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/mahjong/src/RL/pymahjong/env_pymahjong.py:211\u001b[0m, in \u001b[0;36mMahjongEnv.step\u001b[0;34m(self, player_id, action)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_selection_from_action_basetile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43maction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorresponding_tiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAHJONG_TILE_TYPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inst:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot locate action with action = 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/mahjong/src/RL/pymahjong/myEnv_pymahjong.py:379\u001b[0m, in \u001b[0;36mmyMahjongEnv.step\u001b[0;34m(self, player_id, action)\u001b[0m\n\u001b[1;32m    375\u001b[0m tiles_features, oya \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tiles_features(player_id)\n\u001b[1;32m    378\u001b[0m legal_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_legal_actions_mask()\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegal_actions_mask_record[player_id]\u001b[38;5;241m.\u001b[39mappend(legal_actions)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles_features_record[player_id]\u001b[38;5;241m.\u001b[39mappend(tiles_features)\n",
      "File \u001b[0;32m~/Code/mahjong/src/RL/pymahjong/env_pymahjong.py:221\u001b[0m, in \u001b[0;36mMahjongEnv.step\u001b[0;34m(self, player_id, action)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28mprint\u001b[39m(obs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemError\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# riichi step 2\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRIICHI, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPASS_RIICHI)\n",
      "\u001b[0;31mSystemError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.step(3, 45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
